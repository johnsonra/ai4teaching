---
title: "ai4teaching"
format: gfm
---

```{r setup}
#| include: false
library(ai4teaching)
```

The `ai4teaching` package is designed to provide AI-powered, instantaneous feedback to students either while working on asynchronous assignments or as part of an AI-administered oral exam. It was built with the [`learnr`](https://pkgs.rstudio.com/learnr/index.html) package in mind, but it can be used outside of a `learnr` tutorial.


## Installation

`ai4teaching` can be installed with the following command from the `devtools` package:

```
devtools::install_github('johnsonra/ai4teaching')
```


## API keys

Most models currently implemented in `genAI_query` require an API key. This can either be provided in the call to `genAI_query`, or `OPsecrets` will try to find the API key if one isn't provided. The [Usage](#usage) section below has examples for providing API keys. The default environmental variable names for each provider (e.g. Gemini, OpenAI, Anaconda) can be found in the following documentation files:

```
?gemini_query
```

`OPsecrets` also supports the use of 1Password utility, `op`. Additional documentation on how to set up 1Password's `op` utility to work with `OPsecrets` can be found [here](https://github.com/johnsonra/OPsecrets).


## Usage

### Generic queries

To submit a plain query using the default environmental variable, we first need to define the variable, then make the call to `genAI_query`.

```{r, eval=FALSE}
# this is not a real an API key - you'll need to provide your own
Sys.setenv(GEMINI_API_KEY = '123456-xyz')

genAI_query("What is 1 + 1?", model = 'gemini-2.5-pro')
```

    1 + 1 = 2

While this works, it is a bad idea to hard code your API key in your file. If you want to permanently add your key to your R environment, you can edit your default R environment with `usethis::edit_r_envrion()` and add a new line (e.g. `GEMINI_API_KEY = '123456-xyz'`). This is a lot better, but it is still stored in plain text on your filesystem.

Alternately we can include the key as an argument to `genAI_query`:

```{r, eval=FALSE}
# again, this is not a real an API key - you'll need to provide your own
genAI_query("What is 1 + 1?", model = 'gemini-2.5-flash-lite', api_key = '123456-xyz')
```

    1 + 1 = 2

This leaves us with the same problems discussed above. We will use 1Password for the remainder of this README (see [`OPsecrets` documentation](https://github.com/johnsonra/OPsecrets) for more discussion and examples). For example:

```{r, eval=FALSE}
genAI_query("What is 1 + 1?", model = 'gemini-2.5-flash-lite',
            api_key = OPsecrets::get_secret('GEMINI_API_KEY', 'Private', 'Gemini', 'api_key'))
```

    1 + 1 = 2

### Checking answers

This gets us only so far. When providing student feedback, however, we want to provide a question, an answer, and sometimes we want to provide a solution. We also don't want the feedback to be something along the lines of "No, that isn't correct. The right answer is...".

In order to provide feedback, we need to provide the question and the student's answer, along with a sample solution if desired (most large language models won't typically need a sample solution). For example:

```{r, eval=FALSE}
check_answer("Given two variables, `x` and `y`, provide a line of R code that will check if `x` is greater than `y`",
             "x == y")
```

    Incorrect.  Your code checks if `x` is *equal* to `y`, not if it's greater than `y`.  Think about the operators used for comparisons like greater than or less than.

In the example above, the model affirms the solution is correct and gives some additional feedback that might make the solution better. If it is not correct, we would like the model to give us feedback without giving the answer away. `check_answer` also includes a `preamble` argument that instructs the model to give feedback rather than to correct mistakes. The default preamble is

```{r}
cat(construct_preamble())
```

See `?check_answer` and `?construct_preamble` for modifying the default preamble.

### `learnr`

To incorporate this in a `learnr` tutorial, we can use `check_answer` inside of `question_text` as follows:

```{r}
#| echo: false
cat("```{r test_question, echo=FALSE}",
    'question_text("Compare x to y. Is x greater than y?",',
    "              answer_fn(function(value){",
    '                retval <- check_answer("Given two variables, `x` and `y`, provide a line of R code that will check if `x` is greater than `y`",',
    '                                       value,',
    '                                       model = "gemini-2.5-flash-lite",',
    "                                       api_key = OPsecrets::get_secret('GEMINI_API_KEY', 'Private', 'Gemini', 'api_key'))",
    "              }), allow_retry = TRUE)",
    "```", sep = '\n')
```

When rendered in `learnr` an incorrect answer will look something like this:

![](img/learnr_incorrect.png)

If we try again with the correct answer we get the following:

![](img/learnr_correct.png)

## Models

Below is a list of models that have been tested along with some comments. OpenAI is on the short list to implement in this package, but it is not a current option.

* Gemini: Additional (untested) models are available from Gemini, and they may or may not work. See [Gemini documentation](https://ai.google.dev/gemini-api/docs/models/gemini) for a full list.
  * `gemini-3-flash-preview`
  * `gemini-2.5-flash-lite`
  * `gemini-2.5-flash`

<!-- If you get the response, "", the model is currently unavailable due to heavy use. -->

* Anaconda AI Navigator: this offers many open source models of various sizes as well as the option to run everything locally. See the [Anaconda AI Navigator](https://www.anaconda.com/products/ai-navigator) home page for more information. Behavior of these models can be erratic within the context of a `learnr` tutorial.
